{"name": "test_aspect_critic[get_multiturn_data3]", "status": "failed", "statusDetails": {"message": "AssertionError: ❌ AspectCritic score too low: nan. Expected > 0.7. Aspect: nan", "trace": "self = <tests.test_rest_assured.TestRestAssured object at 0x0000019C9C63A420>\nget_llm_wrapper = LangchainLLMWrapper(langchain_llm=ChatOpenAI(...))\nget_multiturn_data = (MultiTurnSample(user_input=[HumanMessage(content='What is Jenkins used for?', metadata=None, type='human'), AIMessage...ns automates the continuous integration, continuous delivery, and continuous deployment steps of a software project.'])\nlogger = <Logger pytest_logger (DEBUG)>\n\n    @allure.story(\"Aspect Critic Evaluation\")\n    @allure.description(\n        \"Validates that the model response remains aspect critic to the reference context for rest assured\")\n    @pytest.mark.asyncio\n    @pytest.mark.parametrize(\"get_multiturn_data\", IronMan.load_test_data(feature_name, \"multiturn\"), indirect=True)\n    async def test_aspect_critic(self, get_llm_wrapper, get_multiturn_data, logger):\n        \"\"\"\n        Test to validate aspect critic score using reusable helper class.\n        \"\"\"\n        logger.info(get_multiturn_data)\n        sample, response = get_multiturn_data\n        evaluator = MetricsEvaluator(get_llm_wrapper)\n        result = await evaluator.get_aspect_critic(sample=sample)\n        logger.info(f\"Aspect Critic Result: {result}\")\n>       self.assertions.assert_aspect_critic(result, threshold=0.7)\n\ntest_rest_assured.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <utilities.assertions.Assertions object at 0x0000019C9C638740>\nresult = {'forgetfulness_aspect_critic': nan}, threshold = 0.7\n\n    def assert_aspect_critic(self, result, threshold: float = 0.7):\n        \"\"\"\n        Validate that the AspectCritic score meets the minimum threshold.\n        Result comes as {'aspectname_aspect_critic': score}.\n        \"\"\"\n        score_list = result.scores\n        score = score_list[0] if score_list else None\n        score = score['forgetfulness_aspect_critic']\n    \n        if score is None:\n            raise ValueError(\"No score found in EvaluationResult\")\n    \n        with allure.step(f\"Validate AspectCritic Score ≥ {threshold}\"):\n>           assert score > threshold, (\n                   ^^^^^^^^^^^^^^^^^\n                f\"❌ AspectCritic score too low: {score}. \"\n                f\"Expected > {threshold}. Aspect: {score}\"\n            )\nE           AssertionError: ❌ AspectCritic score too low: nan. Expected > 0.7. Aspect: nan\n\n..\\utilities\\assertions.py:96: AssertionError"}, "description": "Validates that the model response remains aspect critic to the reference context for rest assured", "steps": [{"name": "Calculate AspectCritic (Aspect Critic:)", "status": "passed", "attachments": [{"name": "User Input", "source": "73b5de92-7535-42eb-bdd3-bda5c6d48d6f-attachment.txt", "type": "text/plain"}, {"name": "AspectCritic Result", "source": "d0164924-0ff6-428f-bc3a-c03e15ed05b4-attachment.txt", "type": "text/plain"}], "start": 1763188381678, "stop": 1763188385751}, {"name": "AspectCritic Result: {'forgetfulness_aspect_critic': nan}", "status": "passed", "start": 1763188385751, "stop": 1763188385751}, {"name": "Validate AspectCritic Score ≥ 0.7", "status": "failed", "statusDetails": {"message": "AssertionError: ❌ AspectCritic score too low: nan. Expected > 0.7. Aspect: nan\n", "trace": "  File \"C:\\Users\\SG0704235\\PycharmProjects\\ragas-openai-pytest\\utilities\\assertions.py\", line 96, in assert_aspect_critic\n    assert score > threshold, (\n           ^^^^^^^^^^^^^^^^^\n"}, "start": 1763188385752, "stop": 1763188385752}], "attachments": [{"name": "log", "source": "87453bc6-ccd0-45e5-b2fe-b104ff267652-attachment.txt", "type": "text/plain"}, {"name": "stdout", "source": "ba457ffe-bb52-4701-9c37-a2e46b510f2e-attachment.txt", "type": "text/plain"}, {"name": "stderr", "source": "84efd02a-e33b-4426-aee6-b8961d7a4dee-attachment.txt", "type": "text/plain"}], "parameters": [{"name": "get_multiturn_data", "value": "{'conversation': [{'role': 'human', 'content': 'What is Jenkins used for?'}, {'role': 'ai', 'content': 'Jenkins is an open-source automation server used to implement continuous integration and continuous delivery (CI/CD) pipelines. It automates build, test, and deployment processes.'}, {'role': 'human', 'content': 'How does Jenkins fit into a CI/CD pipeline?'}, {'role': 'ai', 'content': 'In a CI/CD pipeline, Jenkins automates code compilation, testing, packaging, and deployment whenever code changes are pushed to the repository. It integrates with tools like Git, Maven, Docker, and Kubernetes.'}, {'role': 'human', 'content': 'How do you integrate test automation with Jenkins?'}, {'role': 'ai', 'content': 'You can integrate test automation tools like Playwright, Selenium, or JMeter by creating Jenkins jobs that execute test scripts using build commands or pipelines defined in a Jenkinsfile.'}, {'role': 'human', 'content': 'Can Jenkins run Playwright or API tests automatically?'}, {'role': 'ai', 'content': 'Yes. You can configure Jenkins to install dependencies, run Playwright or API tests headlessly, and publish test reports. This ensures automated validation on every code change.'}, {'role': 'human', 'content': 'How do you configure Jenkins for parallel testing?'}, {'role': 'ai', 'content': 'Parallel testing can be enabled by defining multiple stages or agents in the Jenkinsfile or by using Playwright’s built-in parallel worker configuration. This speeds up execution across multiple environments or browsers.'}], 'reference_contexts': ['Jenkins automates build, test, and deployment workflows.', 'It supports integration with automation tools like Playwright, Selenium, and JMeter.', 'Parallel testing and headless execution can be configured for efficient CI/CD pipelines.'], 'reference': 'Jenkins is a CI/CD automation server that manages code build, test, and deployment workflows. It integrates with automation tools like Playwright, Selenium, and JMeter, supports headless testing, and enables parallel execution for faster pipelines.', 'synthesizer_name': 'multi_turn_ci_cd_jenkins'}"}], "start": 1763188381677, "stop": 1763188385752, "uuid": "bbebd878-23d1-4c2a-8520-b408fbe2f2a4", "historyId": "ce7a22344a7888ce9abecd8b158c865c", "testCaseId": "e566cc050c8a2ea2f2d1829aee5ee020", "fullName": "tests.test_rest_assured.TestRestAssured#test_aspect_critic", "labels": [{"name": "suite", "value": "Rest Assured Evaluation Suite"}, {"name": "story", "value": "Aspect Critic Evaluation"}, {"name": "feature", "value": "Rest Assured"}, {"name": "tag", "value": "asyncio"}, {"name": "parentSuite", "value": "tests"}, {"name": "subSuite", "value": "TestRestAssured"}, {"name": "host", "value": "W4KPW724"}, {"name": "thread", "value": "26856-MainThread"}, {"name": "framework", "value": "pytest"}, {"name": "language", "value": "cpython3"}, {"name": "package", "value": "tests.test_rest_assured"}], "titlePath": ["tests", "test_rest_assured.py", "TestRestAssured"]}