{"name": "test_aspect_critic[get_multiturn_data1]", "status": "broken", "statusDetails": {"message": "AttributeError: 'tuple' object has no attribute 'user_input'", "trace": "self = <tests.test_rest_assured.TestRestAssured object at 0x0000026CBE93EF60>\nget_llm_wrapper = LangchainLLMWrapper(langchain_llm=ChatOpenAI(...))\nget_multiturn_data = (MultiTurnSample(user_input=[HumanMessage(content='What is performance testing?', metadata=None, type='human'), AIMess...t, error rates, and resource utilization to ensure the system meets performance requirements and can scale reliably.'])\nlogger = <Logger pytest_logger (DEBUG)>\n\n    @allure.story(\"Aspect Critic Evaluation\")\n    @allure.description(\n        \"Validates that the model response remains aspect critic to the reference context for rest assured\")\n    @pytest.mark.asyncio\n    @pytest.mark.parametrize(\"get_multiturn_data\", IronMan.load_test_data(feature_name, \"multiturn\"), indirect=True)\n    async def test_aspect_critic(self, get_llm_wrapper, get_multiturn_data, logger):\n        \"\"\"\n        Test to validate aspect critic score using reusable helper class.\n        \"\"\"\n        logger.info(get_multiturn_data)\n        evaluator = MetricsEvaluator(get_llm_wrapper)\n>       result = await evaluator.get_aspect_critic(sample=get_multiturn_data)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntest_rest_assured.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <llm_base.ragas_metrics_evaluator.MetricsEvaluator object at 0x0000026CBEE2EB10>\nsample = (MultiTurnSample(user_input=[HumanMessage(content='What is performance testing?', metadata=None, type='human'), AIMess...t, error rates, and resource utilization to ensure the system meets performance requirements and can scale reliably.'])\n\n    async def get_aspect_critic(self, sample):\n        \"\"\"\n        Compute the AspectCritic score for a given test sample\n        based on the provided critique aspect (e.g., correctness, clarity).\n        \"\"\"\n        with allure.step(f\"Calculate AspectCritic (Aspect Critic:)\"):\n            # Attach user input\n            allure.attach(\n>               str(sample.user_input),\n                    ^^^^^^^^^^^^^^^^^\n                name=\"User Input\",\n                attachment_type=allure.attachment_type.TEXT\n            )\nE           AttributeError: 'tuple' object has no attribute 'user_input'\n\n..\\llm_base\\ragas_metrics_evaluator.py:344: AttributeError"}, "description": "Validates that the model response remains aspect critic to the reference context for rest assured", "steps": [{"name": "Calculate AspectCritic (Aspect Critic:)", "status": "broken", "statusDetails": {"message": "AttributeError: 'tuple' object has no attribute 'user_input'\n", "trace": "  File \"C:\\Users\\SG0704235\\PycharmProjects\\ragas-openai-pytest\\llm_base\\ragas_metrics_evaluator.py\", line 344, in get_aspect_critic\n    str(sample.user_input),\n        ^^^^^^^^^^^^^^^^^\n"}, "start": 1763188314770, "stop": 1763188314770}], "attachments": [{"name": "log", "source": "4513f459-ef3d-4bed-a72e-1980ff0b49b4-attachment.txt", "type": "text/plain"}, {"name": "stdout", "source": "12b8befc-50b8-43e8-8345-db45a0ba57a9-attachment.txt", "type": "text/plain"}], "parameters": [{"name": "get_multiturn_data", "value": "{'conversation': [{'role': 'human', 'content': 'What is performance testing?'}, {'role': 'ai', 'content': 'Performance testing is a type of non-functional testing that measures how an application performs under a specific workload. It checks parameters like speed, scalability, stability, and responsiveness.'}, {'role': 'human', 'content': 'What tools are commonly used for performance testing?'}, {'role': 'ai', 'content': 'Common tools include Apache JMeter, LoadRunner, Gatling, k6, and Locust. Among these, JMeter is widely used for open-source performance testing of web and API applications.'}, {'role': 'human', 'content': 'Can you explain how JMeter works?'}, {'role': 'ai', 'content': 'JMeter simulates multiple virtual users sending requests to a target server and measures how the system responds. It can test web applications, APIs, and databases by recording test plans, executing load scenarios, and collecting performance metrics like throughput, latency, and error rate.'}, {'role': 'human', 'content': 'How do you analyze JMeter test results?'}, {'role': 'ai', 'content': 'You can analyze JMeter results through listeners such as Summary Report, Aggregate Report, and Graph Results. Metrics like response time, error percentage, and throughput help identify performance bottlenecks and scalability issues.'}], 'reference_contexts': ['Performance testing evaluates the systemâ€™s responsiveness, stability, and scalability under load.', 'JMeter is an open-source tool that simulates concurrent users and measures performance metrics.', 'JMeter results can be analyzed through reports and graphs to find bottlenecks.'], 'reference': 'Performance testing ensures an application remains stable, scalable, and responsive under expected load. JMeter helps simulate concurrent user activity and analyze metrics such as throughput, latency, and error rate to identify performance issues.', 'synthesizer_name': 'multi_turn_performance_testing_jmeter'}"}], "start": 1763188314768, "stop": 1763188314772, "uuid": "208d45da-6a86-47c5-8a30-2717773c100d", "historyId": "da514017cdd2f448a90c7df528c20e01", "testCaseId": "e566cc050c8a2ea2f2d1829aee5ee020", "fullName": "tests.test_rest_assured.TestRestAssured#test_aspect_critic", "labels": [{"name": "suite", "value": "Rest Assured Evaluation Suite"}, {"name": "story", "value": "Aspect Critic Evaluation"}, {"name": "feature", "value": "Rest Assured"}, {"name": "tag", "value": "asyncio"}, {"name": "parentSuite", "value": "tests"}, {"name": "subSuite", "value": "TestRestAssured"}, {"name": "host", "value": "W4KPW724"}, {"name": "thread", "value": "24912-MainThread"}, {"name": "framework", "value": "pytest"}, {"name": "language", "value": "cpython3"}, {"name": "package", "value": "tests.test_rest_assured"}], "titlePath": ["tests", "test_rest_assured.py", "TestRestAssured"]}